import os
import re
import pandas as pd
import pickle
import numpy as np
from collections import Counter, defaultdict
from sklearn.preprocessing import LabelEncoder

def ultra_aggressive_clean(text):
    """Remove ALL possible leakage sources - be ruthlessly aggressive"""
    if pd.isna(text):
        return ""
    
    text = str(text).lower()
    
    # 1. Remove ALL prompts (even more patterns)
    prompts_to_remove = [
        r'^[\w\-\@\.]+[:\$#%>]+\s*',  # Any prompt start
        r'\[[\w\s/\-]+\][\$#%>]',     # [anything]$/#/%/>
        r'[\w\-\@\.]+@[\w\-\.]+[:\~]*[\$#%>]+',  # user@host prompts
        r'root@[\w\-]+:[\w/~]*[#\$>]+',  # root prompts
        r'user@[\w\-]+:[\w/~]*[\$>]+',   # user prompts
        r'admin@[\w\-]+:[\w/~]*[\$>]+',  # admin prompts
        r'dev@[\w\-]+:?[\w/~]*[\$>]*',   # dev prompts
        r'\w+@\w+[\$#%>:~]+',            # simple user@host
        r'^\s*[\$#%>]+\s*',              # Leading prompt chars
        r'[\$#%>]+\s*$',                 # Trailing prompt chars
    ]
    
    for pattern in prompts_to_remove:
        text = re.sub(pattern, '', text, flags=re.MULTILINE)
    
    # 2. Remove ALL command output/feedback (major leakage source!)
    output_patterns = [
        r';\s*sleep\s+\d+',                    # sleep delays
        r'\|\|\s*echo\s+[\'\"]*[\w\s]+[\'\"]*',  # || echo anything
        r'&&\s*echo\s+[\'\"]*[\w\s]+[\'\"]*',   # && echo anything
        r'echo\s+[\'\"]*[\w\s\[\]]+[\'\"]*',    # any echo statements
        r'#\s*[\w\s]+',                         # ALL comments
        r'>\s*/dev/null\s*2>&1',                # redirects
        r'2>/dev/null',                         # error redirects
        r'\|\s*tee\s+[\w/\.]+',                # tee commands
        r'\s*\|\s*grep\s+[\w\-]+',             # pipe to grep
        r'\s*\|\s*head\s*(\-\d+)?',            # pipe to head
        r'\s*\|\s*tail\s*(\-\d+)?',            # pipe to tail
        r'\s*\|\s*wc\s*(\-[lwc])?',            # pipe to wc
        r'\s*\|\s*sort',                       # pipe to sort
        r'\s*\|\s*uniq',                       # pipe to uniq
    ]
    
    for pattern in output_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # 3. Remove timestamps and identifiers
    text = re.sub(r'\d{2}:\d{2}:\d{2}', '', text)  # timestamps
    text = re.sub(r'\d{4}-\d{2}-\d{2}', '', text)  # dates
    text = re.sub(r'pid\s*:\s*\d+', '', text)       # process IDs
    
    # 4. Remove class-specific artifacts (expanded list)
    class_artifacts = [
        r'\bzhzh\b', r'\bach\b', r'\bexploit\b', r'\bstep\b',
        r'\bdone\b', r'\bokay\b', r'\bfail\b', r'\berror\b',
        r'\bsuccess\b', r'\bcomplete\b', r'\bfinished\b',
        r'\b(start|end|begin|finish)\b',
        r'\b(attack|recon|scan|probe)\b',  # Remove obvious class words
        r'\b(malicious|suspicious|evil|bad)\b',
        r'\b(hack|hacker|hacking|exploit|payload)\b',
    ]
    
    for artifact in class_artifacts:
        text = re.sub(artifact, '', text, flags=re.IGNORECASE)
    
    # 5. Remove file paths that might be class-specific
    text = re.sub(r'/tmp/[\w\-\.]+', '/tmp/file', text)     # Normalize tmp files
    text = re.sub(r'/home/[\w\-]+', '/home/user', text)     # Normalize home dirs
    text = re.sub(r'/var/[\w/]+', '/var/path', text)        # Normalize var paths
    text = re.sub(r'/etc/[\w\-\.]+', '/etc/file', text)     # Normalize etc files
    
    # 6. Remove/normalize IP addresses and ports
    text = re.sub(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b', 'IP', text)
    text = re.sub(r':\d{1,5}\b', ':PORT', text)  # ports
    
    # 7. Remove URLs
    text = re.sub(r'https?://[\w\-\./]+', 'URL', text)
    
    # 8. Normalize common variables
    text = re.sub(r'\$\{?\w+\}?', 'VAR', text)  # variables like $HOME, ${USER}
    
    # 9. Clean up whitespace and punctuation
    text = re.sub(r'[;|&]+', ' ', text)      # Replace command separators with space
    text = re.sub(r'\s+', ' ', text)         # Collapse whitespace
    text = re.sub(r'[^\w\s\-\./]', ' ', text)  # Remove special chars except common ones
    
    return text.strip()

def extract_core_commands(text):
    """Extract only the core command words, removing ALL arguments"""
    if not text:
        return ""
    
    # Split on whitespace and take only command words
    tokens = text.split()
    
    # Keep only likely command names (not arguments)
    commands = []
    for token in tokens:
        # Skip obvious arguments
        if any(pattern in token for pattern in [
            'IP', 'PORT', 'URL', 'VAR', '/tmp/', '/home/', '/etc/', '/var/',
            '.txt', '.py', '.sh', '.log', '.conf'
        ]):
            continue
        
        # Skip flags and options
        if token.startswith('-') or token.startswith('/'):
            continue
            
        # Skip numbers
        if token.isdigit():
            continue
            
        # Keep if it looks like a command (alphanumeric, common commands)
        if re.match(r'^[a-z][a-z0-9]*$', token) and len(token) > 1:
            commands.append(token)
    
    return ' '.join(commands[:3])  # Take only first 3 commands max

def minimal_tokenize(text):
    """Ultra minimal tokenization - only keep core command words"""
    if not text:
        return []
    
    tokens = text.split()
    
    # Only keep tokens that look like actual commands
    command_tokens = []
    for token in tokens:
        # Must be alphabetic and reasonable length
        if token.isalpha() and 2 <= len(token) <= 15:
            command_tokens.append(token)
    
    return command_tokens[:5]  # Maximum 5 tokens per sequence

def build_minimal_vocab(token_lists, min_freq=20, max_vocab=500):
    """Build extremely small vocabulary to prevent overfitting"""
    counter = Counter()
    for tokens in token_lists:
        counter.update(tokens)
    
    print(f"Total unique tokens before filtering: {len(counter)}")
    
    # Much more aggressive leakage removal
    leakage_indicators = {
        # Obvious class-specific terms
        'nmap', 'netstat', 'ps', 'whoami', 'id', 'uname', 'lsof',
        'ssh', 'scp', 'find', 'cat', 'sudo', 'history', 
        'wget', 'curl', 'nc', 'rm', 'dd', 'useradd',
        # Command outputs
        'done', 'okay', 'fail', 'error', 'success', 'complete',
        # System artifacts
        'root', 'user', 'admin', 'home', 'tmp', 'var', 'etc',
        # Single letters and numbers
        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',
        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
    }
    
    # Only keep very common, non-leaky tokens
    vocab_tokens = ['<PAD>', '<UNK>']
    for tok, freq in counter.most_common():
        if (tok not in leakage_indicators and 
            freq >= min_freq and 
            len(vocab_tokens) < max_vocab and
            len(tok) > 2):  # No short tokens
            vocab_tokens.append(tok)
    
    token2idx = {tok: idx for idx, tok in enumerate(vocab_tokens)}
    
    print(f"Final vocabulary size: {len(token2idx)}")
    print(f"Top tokens: {vocab_tokens[2:22]}")
    
    return token2idx

def analyze_class_separation(df, token_col='tokens'):
    """Analyze if classes can still be separated - if yes, more cleaning needed"""
    print("\n" + "="*60)
    print("ANALYZING CLASS SEPARATION")
    print("="*60)
    
    class_tokens = defaultdict(Counter)
    total_tokens_by_class = defaultdict(int)
    
    # Collect tokens by class
    for _, row in df.iterrows():
        label = row['label']
        tokens = row[token_col]
        class_tokens[label].update(tokens)
        total_tokens_by_class[label] += len(tokens)
    
    print(f"Tokens per class:")
    for label, count in total_tokens_by_class.items():
        print(f"  {label}: {count} tokens")
    
    # Find class-exclusive tokens
    all_labels = list(class_tokens.keys())
    exclusive_tokens = defaultdict(list)
    
    for label in all_labels:
        other_labels = [l for l in all_labels if l != label]
        
        for token, count in class_tokens[label].most_common(50):
            # Check if this token appears in other classes
            other_count = sum(class_tokens[other_label][token] for other_label in other_labels)
            
            # If token is very rare in other classes, it's potentially leaky
            if count > 5 and (other_count == 0 or count / max(other_count, 1) > 5):
                exclusive_tokens[label].append((token, count, other_count))
    
    # Report exclusive tokens
    total_exclusive = 0
    for label, tokens in exclusive_tokens.items():
        if tokens:
            print(f"\n⚠️  {label} has {len(tokens)} potentially exclusive tokens:")
            for token, count, other_count in tokens[:10]:  # Show top 10
                print(f"    '{token}': {count} times (vs {other_count} in other classes)")
            total_exclusive += len(tokens)
    
    if total_exclusive == 0:
        print("✅ No class-exclusive tokens found!")
        return False  # Good - no obvious leakage
    else:
        print(f"\n❌ Found {total_exclusive} potentially leaky tokens across all classes")
        return True  # Bad - still has leakage

def ultra_aggressive_preprocess(csv_path, save_dir, max_seq_len=5):  # VERY short sequences
    """Ultra aggressive preprocessing to eliminate ALL data leakage"""
    os.makedirs(save_dir, exist_ok=True)
    save_prefix = os.path.join(save_dir, "preprocessed_data_ultra_clean")

    print("Loading data...")
    df = pd.read_csv(csv_path)
    
    print(f"Original data shape: {df.shape}")
    df = df.dropna(subset=['tty_contents', 'label'])
    print(f"After removing NaN: {df.shape}")
    
    print("\nOriginal label distribution:")
    print(df['label'].value_counts())
    
    # Apply ultra aggressive cleaning
    print("\nApplying ULTRA AGGRESSIVE cleaning...")
    df['ultra_cleaned'] = df['tty_contents'].apply(ultra_aggressive_clean)
    df['core_commands'] = df['ultra_cleaned'].apply(extract_core_commands)
    
    # Remove empty sequences
    df = df[df['core_commands'].apply(lambda x: len(x.strip()) > 0)]
    print(f"After removing empty sequences: {df.shape}")
    
    # Show examples
    print("\nCleaning examples (first 3 rows):")
    for i in range(min(3, len(df))):
        print(f"Original:     {df.iloc[i]['tty_contents'][:100]}...")
        print(f"Ultra clean:  {df.iloc[i]['ultra_cleaned'][:100]}...")
        print(f"Core cmds:    {df.iloc[i]['core_commands']}")
        print("-" * 80)
    
    # Tokenize with minimal approach
    df['tokens'] = df['core_commands'].apply(minimal_tokenize)
    
    # Remove sequences that are too short or too long
    df = df[df['tokens'].apply(lambda x: 1 <= len(x) <= max_seq_len)]
    print(f"After length filtering: {df.shape}")
    
    # Check sequence statistics
    seq_lengths = df['tokens'].apply(len)
    print(f"\nSequence length stats:")
    print(f"Mean: {seq_lengths.mean():.2f}")
    print(f"Max: {seq_lengths.max()}")
    print(f"Distribution: {seq_lengths.value_counts().sort_index()}")
    
    # Encode labels
    le = LabelEncoder()
    df['label_enc'] = le.fit_transform(df['label'])
    
    print(f"\nFinal label distribution:")
    print(df['label'].value_counts())
    
    # CRITICAL: Analyze class separation BEFORE building vocab
    has_leakage = analyze_class_separation(df, 'tokens')
    
    if has_leakage:
        print("\n🚨 CRITICAL: Still detecting class separation!")
        print("The model will likely still overfit. Consider:")
        print("1. Even more aggressive cleaning")
        print("2. Removing more class-specific tokens")
        print("3. Using only the most generic commands")
    else:
        print("\n✅ Good! Classes appear well-mixed.")
    
    # Build ultra-minimal vocabulary
    print("\nBuilding ultra-minimal vocabulary...")
    token2idx = build_minimal_vocab(df['tokens'], min_freq=30, max_vocab=200)
    
    # Convert to sequences
    sequences = []
    unk_count = 0
    total_tokens = 0
    
    for tokens in df['tokens']:
        seq = []
        for tok in tokens:
            if tok in token2idx:
                seq.append(token2idx[tok])
            else:
                seq.append(token2idx['<UNK>'])
                unk_count += 1
            total_tokens += 1
        sequences.append(seq)
    
    labels = df['label_enc'].tolist()
    
    unk_rate = unk_count / total_tokens if total_tokens > 0 else 0
    print(f"Unknown token rate: {unk_rate:.4f}")
    
    # Check for duplicate sequences (another form of leakage)
    unique_seqs = len(set(str(seq) for seq in sequences))
    uniqueness = unique_seqs / len(sequences)
    print(f"Sequence uniqueness: {uniqueness:.4f} ({unique_seqs}/{len(sequences)})")
    
    if uniqueness < 0.8:
        print("⚠️  Warning: Many duplicate sequences - may still overfit")
    
    # Save data
    max_len_actual = max(len(seq) for seq in sequences) if sequences else 0
    sequences_padded = np.zeros((len(sequences), max_len_actual), dtype=np.int32)
    for i, seq in enumerate(sequences):
        sequences_padded[i, :len(seq)] = seq
    
    np.savez_compressed(save_prefix,
                        sequences=sequences_padded,
                        labels=np.array(labels),
                        sequence_lengths=[len(seq) for seq in sequences])

    with open(save_prefix + '_vocab.pkl', 'wb') as f:
        pickle.dump(token2idx, f)
    with open(save_prefix + '_label_encoder.pkl', 'wb') as f:
        pickle.dump(le, f)

    # Save debugging info
    debug_info = {
        'cleaning_examples': [
            {
                'original': df.iloc[i]['tty_contents'][:200] if i < len(df) else "",
                'ultra_cleaned': df.iloc[i]['ultra_cleaned'][:200] if i < len(df) else "",
                'core_commands': df.iloc[i]['core_commands'] if i < len(df) else "",
                'tokens': df.iloc[i]['tokens'] if i < len(df) else [],
                'label': df.iloc[i]['label'] if i < len(df) else ""
            }
            for i in range(min(10, len(df)))
        ],
        'vocab_sample': dict(list(token2idx.items())[:50]),
        'sequence_samples': sequences[:10],
        'label_samples': labels[:10],
        'stats': {
            'total_sequences': len(sequences),
            'vocab_size': len(token2idx),
            'max_seq_len': max_len_actual,
            'uniqueness_ratio': uniqueness,
            'unk_rate': unk_rate,
            'has_potential_leakage': has_leakage
        }
    }
    
    with open(save_prefix + '_debug.pkl', 'wb') as f:
        pickle.dump(debug_info, f)

    print(f"\n{'='*60}")
    print("ULTRA AGGRESSIVE PREPROCESSING COMPLETE")
    print(f"{'='*60}")
    print(f"Final dataset size: {len(sequences)} sequences")
    print(f"Vocabulary size: {len(token2idx)}")
    print(f"Max sequence length: {max_len_actual}")
    print(f"Files saved:")
    print(f"  - {save_prefix}.npz")
    print(f"  - {save_prefix}_vocab.pkl")
    print(f"  - {save_prefix}_label_encoder.pkl")
    print(f"  - {save_prefix}_debug.pkl")
    
    if has_leakage:
        print(f"\n🚨 WARNING: Model may still achieve unrealistic accuracy!")
        print(f"Consider manual inspection of the debug file.")
    else:
        print(f"\n✅ Preprocessing looks good for realistic evaluation.")
    
    return df, token2idx, le

if __name__ == '__main__':
    csv_path = r"C:\Users\Faster\Downloads\Main_TTYs.csv"
    save_dir = r"C:\Users\Faster\Downloads\Autonomous"
    df, vocab, le = ultra_aggressive_preprocess(csv_path, save_dir)
